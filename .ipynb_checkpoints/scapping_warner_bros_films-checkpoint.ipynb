{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a4e2850",
   "metadata": {},
   "source": [
    "<h2>Importing necessary modules for this project</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "116b23f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e931747",
   "metadata": {},
   "source": [
    "<h3>getting the html text file as response from using request</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb1f9ab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\n",
      "<head>\n",
      "<meta charset=\"UTF-8\"/>\n",
      "<title>The Illusionist (2010 film) - Wikipedia</title>\n",
      "<script>document.documentElement.className=\"client-js\";RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"8f1c7334-4845-40cb-99b8-5\n"
     ]
    }
   ],
   "source": [
    "response = requests.get('https://en.wikipedia.org/wiki/The_Illusionist_(2010_film)')\n",
    "html_text = response.text\n",
    "print(html_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c768752",
   "metadata": {},
   "source": [
    "<h3>pass the text file to Beautiful soup for parsing</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "565fb528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_text, 'lxml')\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0afbf0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "table = soup.find('table', class_='infobox vevent') # selecting the table containing all the info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace8c769",
   "metadata": {},
   "source": [
    "<h3>Getting all the rows in the table which has two columns</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e5eb843",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr><th class=\"infobox-above summary\" colspan=\"2\" style=\"font-size: 125%; font-style: italic;\">The Illusionist</th></tr>,\n",
       " <tr><td class=\"infobox-image\" colspan=\"2\"><a class=\"image\" href=\"/wiki/File:L%27illusionniste-poster.jpg\"><img alt=\"L'illusionniste-poster.jpg\" class=\"thumbborder\" data-file-height=\"267\" data-file-width=\"200\" decoding=\"async\" height=\"267\" src=\"//upload.wikimedia.org/wikipedia/en/7/70/L%27illusionniste-poster.jpg\" width=\"200\"/></a><div class=\"infobox-caption\">Theatrical release poster</div></td></tr>,\n",
       " <tr><td class=\"infobox-full-data description\" colspan=\"2\"><link href=\"mw-data:TemplateStyles:r1066479718\" rel=\"mw-deduplicated-inline-style\"/></td></tr>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = table.find_all('tr')\n",
    "rows[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7c21d234",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_row_data_values(row_datas):\n",
    "    if row_datas.find('li') or row_datas.find('br'):\n",
    "        return [text.replace('\\xa0', '') for text in row_datas.stripped_strings \n",
    "                if ')' not in text  if '(' not in text]\n",
    "    \n",
    "    return row_datas.get_text(strip=True).replace('\\xa0', '')\n",
    "\n",
    "def remove_tags(row_datas):\n",
    "    for sup in row_datas.find_all('sup'):\n",
    "        sup.decompose()\n",
    "        \n",
    "    for span in row_datas.find_all('span'):\n",
    "        span.decompose()\n",
    "        \n",
    "    return row_datas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f5f0e745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': 'The Illusionist',\n",
       " 'French': \"L'Illusionniste\",\n",
       " 'Directed by': 'Sylvain Chomet',\n",
       " 'Screenplay by': ['Henri Marquet', 'Sylvain Chomet'],\n",
       " 'Story by': 'Jacques Tati',\n",
       " 'Based on': 'The Illusionist,by Jacques Tati',\n",
       " 'Produced by': ['Sally Chomet', 'Bob Last'],\n",
       " 'Starring': ['Jean-Claude Donda', 'Eilidh Rankin'],\n",
       " 'Edited by': 'Sylvain Chomet',\n",
       " 'Music by': 'Sylvain Chomet',\n",
       " 'Productioncompanies': ['Pathé', 'Django Films', 'Allied Filmmakers'],\n",
       " 'Distributed by': ['Pathé Distribution', 'Warner Bros. Entertainment UK'],\n",
       " 'Release dates': ['16June2010', '20August2010'],\n",
       " 'Running time': '79 minutes',\n",
       " 'Countries': ['France', 'United Kingdom'],\n",
       " 'Languages': ['French', 'English', 'Gaelic'],\n",
       " 'Budget': '$17 million',\n",
       " 'Box office': '$6 million'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info_table = {}\n",
    "for index, row in enumerate(rows):\n",
    "    if index == 0:\n",
    "        info_table[\"Title\"] = row.text\n",
    "        continue\n",
    "    elif index == 1:\n",
    "        continue\n",
    "    if not row.find('th'):\n",
    "        continue\n",
    "        \n",
    "    row_name = row.find('th').text\n",
    "    row_datas = row.find(\"td\", class_='infobox-data')\n",
    "    cln_row_datas = remove_tags(row_datas)\n",
    "    \n",
    "    if row_name == \"Based on\":\n",
    "        row_data_values = cln_row_datas.get_text(',', strip=True)\n",
    "        info_table[row_name] = row_data_values\n",
    "        continue\n",
    "        \n",
    "    row_data_values = get_row_data_values(cln_row_datas)\n",
    "    \n",
    "    info_table[row_name] = row_data_values\n",
    "\n",
    "info_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b16229a1",
   "metadata": {},
   "source": [
    "<h3>Getting all the links of movie pages of <b>2010-1019</b></h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f990ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "markup = requests.get('https://en.wikipedia.org/wiki/List_of_Warner_Bros._films_(2010–2019)').text\n",
    "soup = BeautifulSoup(markup, 'lxml')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b0f8d7",
   "metadata": {},
   "source": [
    "<h3>Selecting the movie list table</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55651691",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_list = soup.find(\"table\", class_='wikitable sortable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d439631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "375"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_rows = table_list.find_all('tr')\n",
    "len(movie_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "38081d10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Link not found\n",
      "Link not found\n",
      "50\n",
      "Link not found\n",
      "100\n",
      "150\n",
      "Link not found\n",
      "Link not found\n",
      "200\n",
      "Link not found\n",
      "Link not found\n",
      "250\n",
      "Link not found\n",
      "300\n",
      "Link not found\n",
      "350\n"
     ]
    }
   ],
   "source": [
    "movie_paths = []\n",
    "\n",
    "movie_rows = table_list.find_all('tr')\n",
    "\n",
    "for index, movie_row in enumerate(movie_rows):\n",
    "    try:\n",
    "        if index == 0:\n",
    "            continue\n",
    "\n",
    "        movie_title = movie_row.find('i')\n",
    "        relative_path = movie_title.find('a')['href']\n",
    "        abs_path = 'https://en.wikipedia.org' + relative_path\n",
    "\n",
    "        movie_paths.append(abs_path)\n",
    "\n",
    "        if index%50 == 0:\n",
    "            print(index)\n",
    "\n",
    "        time.sleep(2)\n",
    "        \n",
    "    except:\n",
    "        print('Link not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7dcc47d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655009bb",
   "metadata": {},
   "source": [
    "<h3>Lets save the paths to json file to use it later</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "751fee78",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./files/movie_paths.json', \"w\", encoding='utf-8') as file:\n",
    "    json.dump(movie_paths, file, ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e37397b",
   "metadata": {},
   "source": [
    "<h3>lets load the paths</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "23460700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "365"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./files/movie_paths.json', 'r', encoding='utf-8') as file:\n",
    "    movie_paths = json.load(file)\n",
    "\n",
    "len(movie_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "38fb5269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://en.wikipedia.org/wiki/Clash_of_the_Titans_(2010_film)\n"
     ]
    }
   ],
   "source": [
    "print(movie_paths[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c44e2ee",
   "metadata": {},
   "source": [
    "<h3>Lets get the information for each wavepage and store them as a list</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "95cabe7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a function that returns the table information\n",
    "def get_table(soup):\n",
    "    info_table = {}\n",
    "    \n",
    "    table = soup.find('table', class_='infobox vevent')\n",
    "    rows = table.find_all('tr')\n",
    "    \n",
    "    for index, row in enumerate(rows):\n",
    "        if index == 0:\n",
    "            info_table[\"Title\"] = row.text\n",
    "            continue\n",
    "        elif index == 1:\n",
    "            continue\n",
    "        if not row.find('th'):\n",
    "            continue\n",
    "\n",
    "        row_name = row.find('th').text\n",
    "        row_datas = row.find(\"td\", class_='infobox-data')\n",
    "        cln_row_datas = remove_tags(row_datas)\n",
    "\n",
    "        if row_name == \"Based on\":\n",
    "            row_data_values = cln_row_datas.get_text(',', strip=True)\n",
    "            info_table[row_name] = row_data_values\n",
    "            continue\n",
    "\n",
    "        row_data_values = get_row_data_values(cln_row_datas)\n",
    "\n",
    "        info_table[row_name] = row_data_values\n",
    "        \n",
    "    return info_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a2aef502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "41 could not scrap table for path: https://en.wikipedia.orghttps://it.wikipedia.org/wiki/La_bellezza_del_somaro\n",
      "48 could not scrap table for path: https://en.wikipedia.orghttps://pl.wikipedia.org/wiki/Jak_si%C4%99_pozby%C4%87_cellulitu\n",
      "100\n",
      "103 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/%C3%87anakkale_%C3%87ocuklar%C4%B1\n",
      "106 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/O%C4%9Flum_Bak_Git\n",
      "109 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/%C3%87akallarla_Dans_2:_Hastas%C4%B1y%C4%B1z_Dede\n",
      "118 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Hititya:_Madalyonun_S%C4%B1rr%C4%B1\n",
      "138 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Vay_Ba%C5%9F%C4%B1ma_Gelenler\n",
      "145 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Kedi_%C3%96zledi\n",
      "147 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Senin_Hikayen\n",
      "148 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Kad%C4%B1n_%C4%B0%C5%9Fi:_Banka_Soygunu\n",
      "157 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Zaman_Makinesi_1973\n",
      "159 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Hayat_Sana_G%C3%BCzel_(film,_2014)\n",
      "161 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Panzehir_(film)\n",
      "171 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Dabbe:_Zehr-i_Cin\n",
      "185 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/K%C4%B1r%C4%B1ml%C4%B1_(film)\n",
      "189 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Yusuf_Yusuf_(film)\n",
      "190 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/K%C3%B6stebekgiller:_Perili_Orman\n",
      "191 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Sevimli_Tehlikeli\n",
      "195 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/8_Saniye\n",
      "200\n",
      "221 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Git_Ba%C5%9F%C4%B1mdan\n",
      "230 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Delibal\n",
      "231 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/K%C3%B6stebekgiller_2:_G%C3%B6lgenin_T%C4%B1ls%C4%B1m%C4%B1\n",
      "232 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Her_%C5%9Eey_A%C5%9Fktan_(film)\n",
      "234 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Osman_Pazarlama\n",
      "256 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/Can%C4%B1m_Karde%C5%9Fim_Benim\n",
      "274 could not scrap table for path: https://en.wikipedia.orghttps://tr.wikipedia.org/wiki/K%C4%B1r%C4%B1k_Kalpler_Bankas%C4%B1\n",
      "291 could not scrap table for path: https://en.wikipedia.orghttps://pt.wikipedia.org/wiki/Bingo:_O_Rei_das_Manh%C3%A3s\n",
      "300\n",
      "319 could not scrap table for path: https://en.wikipedia.org/w/index.php?title=Kabir_Azab%C4%B1&action=edit&redlink=1\n",
      "331 could not scrap table for path: https://en.wikipedia.orghttps://pt.wikipedia.org/wiki/Exterminadores_do_Al%C3%A9m_contra_a_Loira_do_Banheiro\n",
      "357 could not scrap table for path: https://en.wikipedia.org/wiki/Western_Stars#Film\n"
     ]
    }
   ],
   "source": [
    "movie_dataset = []\n",
    "for index, path in enumerate(movie_paths):\n",
    "    try:\n",
    "        info_table = {}\n",
    "\n",
    "        markup = requests.get(path).text\n",
    "        soup = BeautifulSoup(markup, 'lxml')\n",
    "\n",
    "        table = get_table(soup)\n",
    "        title = path.split('/')[-1]\n",
    "\n",
    "        info_table[title] = table\n",
    "        movie_dataset.append(info_table)\n",
    "        time.sleep(2)\n",
    "        \n",
    "        if index % 100 == 0:\n",
    "            print(index)\n",
    "            \n",
    "    except:\n",
    "        print(f'{index} could not scrap table for path: {path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01266c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(movie_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6ddcef5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Rampage_(2018_film)': {'Title': 'Rampage',\n",
       "  'Directed by': 'Brad Peyton',\n",
       "  'Screenplay by': ['Ryan Engle',\n",
       "   'Carlton Cuse',\n",
       "   'Ryan J. Condal',\n",
       "   'Adam Sztykiel'],\n",
       "  'Story by': 'Ryan Engle',\n",
       "  'Based on': 'Rampage,by,Midway Games',\n",
       "  'Produced by': ['Dwayne Johnson',\n",
       "   'Brad Peyton',\n",
       "   'Beau Flynn',\n",
       "   'John Rickard',\n",
       "   'Hiram Garcia'],\n",
       "  'Starring': ['Dwayne Johnson',\n",
       "   'Naomie Harris',\n",
       "   'Malin Åkerman',\n",
       "   'Joe Manganiello',\n",
       "   'Jake Lacy',\n",
       "   'Marley Shelton',\n",
       "   'Jeffrey Dean Morgan'],\n",
       "  'Cinematography': 'Jaron Presant',\n",
       "  'Edited by': ['Jim May', 'Bob Ducsay'],\n",
       "  'Music by': 'Andrew Lockington',\n",
       "  'Productioncompanies': ['New Line Cinema',\n",
       "   'Access Entertainment',\n",
       "   'Dune Entertainment',\n",
       "   'Flynn Picture Company',\n",
       "   'Wrigley Pictures',\n",
       "   'ASAP Entertainment',\n",
       "   'Seven Bucks Productions'],\n",
       "  'Distributed by': 'Warner Bros. Pictures',\n",
       "  'Release dates': ['April4,2018', 'Microsoft Theater', 'April13,2018'],\n",
       "  'Running time': '107 minutes',\n",
       "  'Country': 'United States',\n",
       "  'Language': 'English',\n",
       "  'Budget': '$120–140 million',\n",
       "  'Box office': '$428 million'}}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_dataset[-50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c10783af",
   "metadata": {},
   "source": [
    "<h3>From 365 webpages we were able to scrap 335 pages. The ones which are not written in English or \n",
    "is not a movie. Now lets save the data into a json file</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2ab56aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./files/movie_dataset.json', \"w\", encoding='utf-8') as file:\n",
    "    json.dump(movie_dataset, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94910474",
   "metadata": {},
   "source": [
    "<h1>The data collection part is now completed right now we need to clean it</h1>\n",
    "<H2><b>Check the data_cleaning notebook for cleaning the movie_dataset</b><H2>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
